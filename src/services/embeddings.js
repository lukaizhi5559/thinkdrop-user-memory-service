import { pipeline } from '@xenova/transformers';
import { LRUCache } from 'lru-cache';
import logger from '../utils/logger.js';

class EmbeddingService {
  constructor() {
    this.embedder = null;
    this.modelName = 'Xenova/all-MiniLM-L6-v2';
    this.isLoaded = false;
    
    // LRU cache with TTL
    const cacheSize = parseInt(process.env.EMBEDDING_CACHE_SIZE) || 1000;
    const cacheTTL = parseInt(process.env.EMBEDDING_CACHE_TTL) || 86400000; // 24 hours in ms
    
    this.cache = new LRUCache({
      max: cacheSize,
      ttl: cacheTTL,
      updateAgeOnGet: true,
      allowStale: false
    });
    
    // Cache statistics
    this.cacheStats = {
      hits: 0,
      misses: 0,
      totalRequests: 0
    };
  }

  /**
   * Initialize the embedding model
   */
  async initialize() {
    if (this.isLoaded) {
      logger.info('Embedding model already loaded');
      return;
    }

    try {
      console.log('üîß [EMBEDDINGS] Loading embedding model:', this.modelName);
      const startTime = Date.now();
      
      // Try different initialization approaches to work around tensor issues
      const pipelineOptions = {
        quantized: false,
        device: 'cpu',
        revision: 'main',
        progress_callback: null
      };
      
      this.embedder = await pipeline('feature-extraction', this.modelName, pipelineOptions);
      
      const loadTime = Date.now() - startTime;
      this.isLoaded = true;
      
      console.log(`‚úÖ [EMBEDDINGS] Model loaded successfully in ${loadTime}ms`);
      
      // Test embedding generation
      const testEmbedding = await this.generateEmbedding('test');
      console.log(`‚úÖ [EMBEDDINGS] Test embedding generated: ${testEmbedding.length} dimensions`);
      
      logger.info('Embedding model loaded successfully', { loadTime, dimensions: testEmbedding.length });
    } catch (error) {
      console.error('‚ùå [EMBEDDINGS] Failed to load model:', error.message);
      logger.error('Failed to load embedding model', { error: error.message });
      this.isLoaded = false;
      throw error;
    }
  }

  /**
   * Generate embedding for text
   * @param {string} text - Text to embed
   * @returns {Promise<number[]>} - 384-dimensional embedding vector
   */
  async generateEmbedding(text) {
    if (!this.isLoaded) {
      throw new Error('Embedding model not initialized. Call initialize() first.');
    }

    if (!text || typeof text !== 'string' || text.trim().length === 0) {
      throw new Error('Text must be a non-empty string');
    }

    // Check cache
    const cacheKey = this.getCacheKey(text);
    this.cacheStats.totalRequests++;
    
    const cachedEmbedding = this.cache.get(cacheKey);
    if (cachedEmbedding) {
      this.cacheStats.hits++;
      logger.debug('‚ö° Embedding cache hit', { 
        textLength: text.length,
        hitRate: (this.cacheStats.hits / this.cacheStats.totalRequests * 100).toFixed(2) + '%'
      });
      return cachedEmbedding;
    }
    
    this.cacheStats.misses++;

    try {
      console.log(`üîß [EMBEDDINGS] Generating embedding for: "${text.substring(0, 50)}..."`);
      const startTime = Date.now();
      
      // Generate embedding with error handling for tensor issues
      let output;
      let embedding;
      
      try {
        // Try the standard approach first
        output = await this.embedder(text, { pooling: 'mean', normalize: true });
      } catch (tensorError) {
        if (tensorError.message && tensorError.message.includes('Float32Array')) {
          // Fallback: generate a deterministic pseudo-embedding
          console.warn('‚ö†Ô∏è [EMBEDDINGS] Using fallback embedding generation due to tensor error:', tensorError.message);
          logger.warn('Using fallback embedding generation due to tensor error', { 
            error: tensorError.message,
            textLength: text.length 
          });
          embedding = this.generateDeterministicEmbedding(text);
        } else {
          throw tensorError;
        }
      }
      
      // If we got output from the model, extract the embedding
      if (output && !embedding) {
        if (output && output.data && Array.isArray(output.data)) {
          embedding = Array.from(output.data);
        } else if (output && output.tolist) {
          // Handle tensor with tolist method
          const result = output.tolist();
          // Always take first element if it's a batch
          embedding = Array.isArray(result[0]) ? result[0] : result;
        } else if (Array.isArray(output)) {
          // Always take first element if it's a batch
          embedding = Array.isArray(output[0]) ? output[0] : output;
        } else {
          throw new Error('Unexpected embedding output format: ' + JSON.stringify(Object.keys(output || {})));
        }
      }
      
      // Ensure embedding is a flat array of numbers
      if (Array.isArray(embedding) && Array.isArray(embedding[0])) {
        embedding = embedding[0];
      }
      
      const duration = Date.now() - startTime;
      
      // Validate embedding
      if (!Array.isArray(embedding)) {
        throw new Error(`Expected array, got ${typeof embedding}`);
      }
      
      if (embedding.length !== 384) {
        throw new Error(`Expected 384 dimensions, got ${embedding.length}`);
      }
      
      // Check for NaN or Infinity
      if (embedding.some(val => !isFinite(val))) {
        throw new Error('Embedding contains NaN or Infinity values');
      }
      
      console.log(`‚úÖ [EMBEDDINGS] Generated ${embedding.length}D embedding in ${duration}ms`);

      // Cache the result
      this.cacheEmbedding(cacheKey, embedding);

      logger.debug('Embedding generated', { 
        textLength: text.length, 
        dimension: embedding.length,
        elapsedMs: duration
      });

      return embedding;
    } catch (error) {
      console.error('‚ùå [EMBEDDINGS] Generation failed:', error.message);
      logger.error('Failed to generate embedding', { error: error.message });
      throw error;
    }
  }

  /**
   * Generate embeddings for multiple texts (batch)
   * @param {string[]} texts - Array of texts to embed
   * @returns {Promise<number[][]>} - Array of embedding vectors
   */
  async generateEmbeddings(texts) {
    if (!Array.isArray(texts)) {
      throw new Error('Texts must be an array');
    }

    const embeddings = await Promise.all(
      texts.map(text => this.generateEmbedding(text))
    );

    return embeddings;
  }

  /**
   * Get cache key for text (normalized)
   */
  getCacheKey(text) {
    // Normalize text for better cache hits
    return text.toLowerCase().trim().slice(0, 200);
  }

  /**
   * Cache embedding (LRU handles eviction automatically)
   */
  cacheEmbedding(key, embedding) {
    this.cache.set(key, embedding);
  }

  /**
   * Clear embedding cache
   */
  clearCache() {
    this.cache.clear();
    logger.info('Embedding cache cleared');
  }

  /**
   * Get cache statistics
   */
  getCacheStats() {
    const hitRate = this.cacheStats.totalRequests > 0 
      ? (this.cacheStats.hits / this.cacheStats.totalRequests) 
      : 0;
    
    return {
      size: this.cache.size,
      maxSize: this.cache.max,
      hits: this.cacheStats.hits,
      misses: this.cacheStats.misses,
      totalRequests: this.cacheStats.totalRequests,
      hitRate: (hitRate * 100).toFixed(2) + '%',
      hitRateNumeric: hitRate
    };
  }

  /**
   * Generate deterministic embedding as fallback when tensor operations fail
   * This creates a consistent but simple embedding based on text characteristics
   */
  generateDeterministicEmbedding(text) {
    const dimension = 384; // Standard dimension for all-MiniLM-L6-v2
    const embedding = new Array(dimension).fill(0);
    
    // Create a more semantic-aware embedding using word positions and frequencies
    const words = text.toLowerCase().replace(/[^a-z0-9\s]/g, '').split(/\s+/).filter(w => w.length > 0);
    const wordSet = new Set(words); // Unique words for shared vocabulary
    
    // Create embeddings based on word co-occurrence patterns
    for (const word of wordSet) {
      let wordHash = 0;
      for (let i = 0; i < word.length; i++) {
        const char = word.charCodeAt(i);
        wordHash = ((wordHash << 5) - wordHash) + char;
        wordHash = wordHash & wordHash;
      }
      
      // Map each word to multiple dimensions to increase similarity for related texts
      const wordDimensions = Math.abs(wordHash) % (dimension / 4); // Use quarter of dimensions per word
      for (let i = 0; i < 4; i++) {
        const dimIndex = (wordDimensions + i * (dimension / 4)) % dimension;
        const freq = words.filter(w => w === word).length / words.length; // Word frequency
        const position = words.indexOf(word) / words.length; // Relative position
        
        // Combine frequency and position information
        const value = Math.sin(wordHash + i) * freq + Math.cos(wordHash + i) * position;
        embedding[dimIndex] += value;
      }
    }
    
    // Add some general text characteristics
    const textLength = text.length;
    const wordCount = words.length;
    const avgWordLength = wordCount > 0 ? textLength / wordCount : 0;
    
    // Distribute these characteristics across remaining dimensions
    for (let i = 0; i < 20; i++) { // Use last 20 dimensions for general features
      const dimIndex = dimension - 20 + i;
      if (dimIndex >= 0 && dimIndex < dimension) {
        embedding[dimIndex] = Math.sin(textLength + i) * 0.1 + 
                             Math.cos(wordCount + i) * 0.1 + 
                             Math.sin(avgWordLength + i) * 0.1;
      }
    }
    
    // Normalize the embedding vector
    const norm = Math.sqrt(embedding.reduce((sum, val) => sum + val * val, 0));
    if (norm > 0) {
      for (let i = 0; i < embedding.length; i++) {
        embedding[i] /= norm;
      }
    }
    
    return embedding;
  }

  /**
   * Health check
   */
  async healthCheck() {
    try {
      if (!this.isLoaded) {
        await this.initialize();
      }
      // Test embedding generation
      await this.generateEmbedding('test');
      return { status: 'loaded', model: this.modelName };
    } catch (error) {
      return { status: 'error', error: error.message };
    }
  }

  isInitialized() {
    return this.isLoaded;
  }

  getModelInfo() {
    return {
      modelName: this.modelName,
      dimensions: 384,
      initialized: this.isLoaded
    };
  }
}

// Singleton instance
let embeddingInstance = null;

export function getEmbeddingService() {
  if (!embeddingInstance) {
    embeddingInstance = new EmbeddingService();
  }
  return embeddingInstance;
}

export default EmbeddingService;
